{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9618a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_1DM():\n",
    "    model1dM = Sequential()\n",
    "    model1dM.add(Conv1D(32, kernel_size=5, input_shape = (4098, 3)))\n",
    "    model1dM.add(Conv1D(32, kernel_size=5))    # added new\n",
    "    model1dM.add(MaxPooling1D(pool_size=(2)))\n",
    "    model1dM.add(Conv1D(64, kernel_size=5))\n",
    "    model1dM.add(Conv1D(64, kernel_size=5))    # added new\n",
    "    model1dM.add(MaxPooling1D(pool_size=(2)))\n",
    "    model1dM.add(Conv1D(128, kernel_size=3))\n",
    "    model1dM.add(Conv1D(128, kernel_size=3))    # added new and changed to 128 from 64\n",
    "    model1dM.add(MaxPooling1D(pool_size=(2)))\n",
    "    model1dM.add(Dropout(0.25))\n",
    "    model1dM.add(Flatten())\n",
    "    model1dM.add(Dense(128, activation='relu',kernel_regularizer=keras.regularizers.l2(l=0.1)))\n",
    "    model1dM.add(Dropout(0.5))\n",
    "    model1dM.add(Dense(1, activation='sigmoid'))\n",
    "    model1dM.compile(loss='binary_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "    return model1dM\n",
    "                     \n",
    "def model_BNM():\n",
    "                     \n",
    "    modelBNM = Sequential()\n",
    "    modelBNM.add(Conv1D(32, kernel_size=5, input_shape = (4098, 3)))\n",
    "    modelBNM.add(MaxPooling1D(pool_size=(2)))\n",
    "    modelBNM.add(Conv1D(32, kernel_size=5))\n",
    "    modelBNM.add(MaxPooling1D(pool_size=(2)))\n",
    "    modelBNM.add(Conv1D(64, kernel_size=3))\n",
    "    modelBNM.add(MaxPooling1D(pool_size=(2)))\n",
    "    modelBNM.add(Dropout(0.25))\n",
    "    modelBNM.add(Flatten())\n",
    "    # we can think of this chunk as the input layer\n",
    "    modelBNM.add(Dense(128))\n",
    "    modelBNM.add(BatchNormalization())\n",
    "    modelBNM.add(Activation('relu'))\n",
    "    modelBNM.add(Dropout(0.5))\n",
    "\n",
    "    # we can think of this chunk as the hidden layer    \n",
    "    modelBNM.add(Dense(64))\n",
    "    modelBNM.add(BatchNormalization())\n",
    "    modelBNM.add(Activation('relu'))\n",
    "    modelBNM.add(Dropout(0.5))\n",
    "\n",
    "    # we can think of this chunk as the output layer\n",
    "    modelBNM.add(Dense(1))\n",
    "    modelBNM.add(BatchNormalization())\n",
    "    modelBNM.add(Activation('sigmoid'))\n",
    "\n",
    "    # setting up the optimization of our weights \n",
    "    #sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    modelBNM.compile(loss='binary_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "    return modelBNM\n",
    "# running the fitting\n",
    "                     \n",
    "def BN_Regularization():\n",
    "                    \n",
    "# instantiate model\n",
    "    modelBNrm = Sequential()\n",
    "    modelBNrm.add(Conv1D(32, kernel_size=5, input_shape = (4098, 3)))\n",
    "    modelBNrm.add(MaxPooling1D(pool_size=(2)))\n",
    "    modelBNrm.add(Conv1D(32, kernel_size=5))\n",
    "    modelBNrm.add(MaxPooling1D(pool_size=(2)))\n",
    "    modelBNrm.add(Conv1D(64, kernel_size=3))\n",
    "    modelBNrm.add(MaxPooling1D(pool_size=(2)))\n",
    "    modelBNrm.add(Dropout(0.25))\n",
    "    modelBNrm.add(Flatten())\n",
    "    # we can think of this chunk as the input layer\n",
    "    modelBNrm.add(Dense(128,kernel_regularizer=keras.regularizers.l2(l=0.1)))\n",
    "    modelBNrm.add(BatchNormalization())\n",
    "    modelBNrm.add(Activation('relu'))\n",
    "    modelBNrm.add(Dropout(0.5))\n",
    "\n",
    "    # we can think of this chunk as the hidden layer    \n",
    "    modelBNrm.add(Dense(64,kernel_regularizer=keras.regularizers.l2(l=0.1)))\n",
    "    modelBNrm.add(BatchNormalization())\n",
    "    modelBNrm.add(Activation('relu'))\n",
    "    modelBNrm.add(Dropout(0.5))\n",
    "\n",
    "    # we can think of this chunk as the output layer\n",
    "    modelBNrm.add(Dense(1,kernel_regularizer=keras.regularizers.l2(l=0.1)))\n",
    "    modelBNrm.add(BatchNormalization())\n",
    "    modelBNrm.add(Activation('sigmoid'))\n",
    "\n",
    "    # setting up the optimization of our weights \n",
    "    #sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    modelBNrm.compile(loss='binary_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "    # running the fitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "154e042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Wrapper\n",
    "import tensorflow as tf\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "Model1DM = tf.keras.wrappers.scikit_learn.KerasClassifier(\n",
    "                            model_1DM,\n",
    "                           epochs=50, \n",
    "                            verbose=False)\n",
    "\n",
    "Model_BNM = tf.keras.wrappers.scikit_learn.KerasClassifier(\n",
    "                            model_BNM,\n",
    "                           epochs=50,\n",
    "                            verbose=False)\n",
    "\n",
    "Model_BN_Regularization = tf.keras.wrappers.scikit_learn.KerasClassifier(\n",
    "                            BN_Regularization,\n",
    "                           epochs=50,\n",
    "                            verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72126b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model1DM._estimator_type = \"classifier\"\n",
    "Model_BNM._estimator_type = \"classifier\"\n",
    "Model_BN_Regularization._estimator_type = \"classifier\"\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "307c2850",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting = VotingClassifier(\n",
    "             estimators=[('model1DM',Model1DM),\n",
    "                         ('Model_BNM', Model_BNM), \n",
    "                         ('Model_BN_Regularization', Model_BN_Regularization)], \n",
    "    \n",
    "             voting='soft',\n",
    "             flatten_transform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05af8374",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-c9d7c4dd4fee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Ensemble learning training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mModel1DM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModel_BNM\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mModel_BN_Regularization\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvoting\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Ensemble learning training\n",
    "for clf in (Model1DM, Model_BNM,Model_BN_Regularization, voting):\n",
    "    clf.fit(final_a_ary, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "797e5019",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = clf.predict(final_b_bry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39396d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing accuracy score\n",
    "\n",
    "#print(clf.__class__.__name__, accuracy_score(final_b_ary, y_pred))\n",
    "#y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbe1d04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
